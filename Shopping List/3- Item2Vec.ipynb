{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1 style=\"font-size:35px; font-family: 'Times New Roman'; letter-spacing: 0.1em;\">Item2Vec </h1></center>\n",
    "\n",
    "\n",
    "Our recommender model is based on the Item2Vec specification, which is a direct adaptation of the Word2Vec model introduced by Mikolov (2013) at Google. recommend products to users based on their historical purchasing behavior. By grouping users into clusters, this model aims to provide more personalized recommendations tailored to specific customer segments\n",
    "\n",
    "In this notebook, we will train 13 different Item2Vec models, one for each identified cluster. To ensure that our recommendations are informative, we will restrict the data to only include orders containing at least 4 items. This restriction will provide the recommender with sufficient information, in addition to the cluster to which the user belongs.\n",
    "\n",
    "The overall goal of the code is to prepare customer order data, split it into training and testing sets, build an Item2Vec model for each cluster of customers based on their purchasing behavior, and save the models for later recommendations. The use of clustering allows the model to tailor recommendations to specific user segments, improving the relevance of the suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Overview of Item2Vec:**\n",
    "\n",
    "- **Item2Vec**: This is a modification of **Word2Vec**, a model developed by Google for natural language processing. In **Word2Vec**, the model learns vector representations for words based on the surrounding words (context) in sentences.\n",
    "  - In **Item2Vec**, instead of words, we treat products as \"words\" and customer orders as \"sentences.\" By analyzing the sequences of products purchased together, the model learns vector embeddings for each product.\n",
    "  - These embeddings can be used to find products that are commonly purchased together and recommend them to users.\n",
    "\n",
    "- **Clustering**: Users are grouped into different clusters based on their purchasing habits (derived from KMeans clustering done earlier). For each cluster, a separate **Item2Vec** model is trained.\n",
    "\n",
    "### **steps** :\n",
    "\n",
    "1. **Data Preparation**: Purchase histories are prepared by filtering out small orders and aggregating products bought together in each order.\n",
    "2. **Item2Vec Training**: A separate **Item2Vec** model is trained for each user cluster. This helps the model learn product embeddings based on products frequently bought together.\n",
    "3. **Saving Models**: The trained models are saved to disk for later use in making recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "from os import listdir\n",
    "from typing import List\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('Data/products.csv')\n",
    "cluster_data = pq.read_table('Savings/dummy_k18.parquet').to_pandas()\n",
    "cluster_data_named = pd.merge(cluster_data, products, on='product_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>cluster</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>33120</td>\n",
       "      <td>3</td>\n",
       "      <td>202279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>28985</td>\n",
       "      <td>3</td>\n",
       "      <td>202279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9327</td>\n",
       "      <td>3</td>\n",
       "      <td>202279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>45918</td>\n",
       "      <td>3</td>\n",
       "      <td>202279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>30035</td>\n",
       "      <td>3</td>\n",
       "      <td>202279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  product_id  cluster  user_id\n",
       "0         2       33120        3   202279\n",
       "1         2       28985        3   202279\n",
       "2         2        9327        3   202279\n",
       "3         2       45918        3   202279\n",
       "4         2       30035        3   202279"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_data.head()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data_named['product_id'] = cluster_data_named['product_id'].astype(str)\n",
    "cluster_data_named['user_id'] = cluster_data_named['user_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function filters the DataFrame to return only the rows belonging to a specific cluster.\n",
    "def filter_data_by_cluster(data: pd.DataFrame, cluster_num: int):\n",
    "    return data.loc[data['cluster'] == cluster_num, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_separated = [filter_data_by_cluster(cluster_data_named, cluster_num) for cluster_num in range(0, len(cluster_data_named['cluster'].unique()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function randomly splits users in each cluster into training and testing sets based on a specified training rate (e.g., 75%).\n",
    "def split_users_in_cluster(cluster_data: pd.DataFrame, train_rate: float):\n",
    "    unique_users = cluster_data['user_id'].unique()\n",
    "    train_users = np.random.choice(unique_users, round(len(unique_users)*train_rate), False).tolist()\n",
    "    test_users = [user for user in unique_users if user not in train_users]\n",
    "    return train_users, test_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product Lookup: This function creates a dictionary that maps product_id to product_name. This dictionary is saved as a pickle file and will be useful when we want to show the actual product names instead of just their IDs during recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save product lookup\n",
    "def save_product_lookup(products: pd.DataFrame):\n",
    "    product_lookup = dict(zip(products['product_id'].astype(str), products['product_name'].tolist()))\n",
    "    with open('Savings/product_lookup.pkl', 'wb') as file:\n",
    "        pickle.dump(product_lookup, file)\n",
    "\n",
    "save_product_lookup(products)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ThIS function prepare the purchase history for training the Item2Vec model.\n",
    "get_orders_from_cluster: Groups the purchase data by user_id and order_id and aggregates the product_ids into lists. Each list represents an order made by a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate purchase history for each cluster\n",
    "def get_orders_from_cluster(cluster):\n",
    "    return cluster.groupby(['user_id', 'order_id'])['product_id'].apply(list).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function generates a purchase history for each cluster, including only orders with more than 3 items (to ensure sufficient data). These aggregated orders will serve as the input for the Item2Vec model, where sequences of products in the same order are used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_purchase_history_in_cluster(cluster: pd.DataFrame):\n",
    "    purchase_history = get_orders_from_cluster(cluster)\n",
    "    filtered_purchase_history = [\n",
    "        purchase for purchase in purchase_history if len(purchase) > 3]\n",
    "    return filtered_purchase_history\n",
    "\n",
    "\n",
    "purchase_history_in_cluster = [generate_purchase_history_in_cluster(cluster) for cluster in clusters_separated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Item2Vec Model**: The **Word2Vec** model is trained using the aggregated purchase histories. Key parameters:\n",
    "  - **`window=3`**: This controls the context window size (i.e., how many products on either side are considered when training the embeddings).\n",
    "  - **`sg=1`**: This enables the **Skip-gram** model, which predicts surrounding words (products) for a given word (product).\n",
    "  - **`vector_size=100`**: The dimensionality of the embedding vectors (how many dimensions each product is represented by).\n",
    "  - **`epochs=10`**: The model is trained for 10 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train Item2Vec model\n",
    "def build_item2vec_model(purchases_data):\n",
    "    model = Word2Vec(window=3, sg=1, hs=0, vector_size=100, negative=10, alpha=0.03, min_alpha=0.0007, seed=28101997, workers=6)\n",
    "    model.build_vocab(purchases_data, progress_per=200)\n",
    "    model.train(purchases_data, total_examples=model.corpus_count, epochs=10, report_delay=1)\n",
    "    return model\n",
    "\n",
    "models = [build_item2vec_model(purchase_history) for purchase_history in purchase_history_in_cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model for cluster 0 successfully saved.',\n",
       " 'Model for cluster 1 successfully saved.',\n",
       " 'Model for cluster 2 successfully saved.',\n",
       " 'Model for cluster 3 successfully saved.',\n",
       " 'Model for cluster 4 successfully saved.',\n",
       " 'Model for cluster 5 successfully saved.',\n",
       " 'Model for cluster 6 successfully saved.',\n",
       " 'Model for cluster 7 successfully saved.',\n",
       " 'Model for cluster 8 successfully saved.',\n",
       " 'Model for cluster 9 successfully saved.',\n",
       " 'Model for cluster 10 successfully saved.',\n",
       " 'Model for cluster 11 successfully saved.',\n",
       " 'Model for cluster 12 successfully saved.',\n",
       " 'Model for cluster 13 successfully saved.',\n",
       " 'Model for cluster 14 successfully saved.',\n",
       " 'Model for cluster 15 successfully saved.',\n",
       " 'Model for cluster 16 successfully saved.',\n",
       " 'Model for cluster 17 successfully saved.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save models\n",
    "def save_cluster_model(model, cluster_id: int):\n",
    "    model.save(f'Models Clusters/model_cluster_{cluster_id}.model')\n",
    "    return f\"Model for cluster {cluster_id} successfully saved.\"\n",
    "\n",
    "\n",
    "[save_cluster_model(models[i], i) for i in range(len(models))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
